{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Search Update Notebook\n",
    "\n",
    "This notebook is used to update the elastic search index with the latest datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/rbilleci/pandora.git\n",
      "  Cloning https://github.com/rbilleci/pandora.git to /tmp/pip-req-build-5x2zec59\n",
      "  Running command git clone -q https://github.com/rbilleci/pandora.git /tmp/pip-req-build-5x2zec59\n",
      "Requirement already satisfied (use --upgrade to upgrade): pandora==0.1.0 from git+https://github.com/rbilleci/pandora.git in /opt/conda/lib/python3.7/site-packages\n",
      "Requirement already satisfied: pandas~=1.2.1 in /opt/conda/lib/python3.7/site-packages (from pandora==0.1.0) (1.2.2)\n",
      "Requirement already satisfied: fnvhash~=0.1.0 in /opt/conda/lib/python3.7/site-packages (from pandora==0.1.0) (0.1.0)\n",
      "Requirement already satisfied: scikit-learn~=0.24.1 in /opt/conda/lib/python3.7/site-packages (from pandora==0.1.0) (0.24.1)\n",
      "Requirement already satisfied: workalendar~=14.1.0 in /opt/conda/lib/python3.7/site-packages (from pandora==0.1.0) (14.1.0)\n",
      "Requirement already satisfied: category-encoders~=2.2.2 in /opt/conda/lib/python3.7/site-packages (from pandora==0.1.0) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas~=1.2.1->pandora==0.1.0) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.7/site-packages (from pandas~=1.2.1->pandora==0.1.0) (1.18.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas~=1.2.1->pandora==0.1.0) (2019.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn~=0.24.1->pandora==0.1.0) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn~=0.24.1->pandora==0.1.0) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn~=0.24.1->pandora==0.1.0) (1.4.1)\n",
      "Requirement already satisfied: setuptools>=1.0 in /opt/conda/lib/python3.7/site-packages (from workalendar~=14.1.0->pandora==0.1.0) (45.2.0.post20200210)\n",
      "Requirement already satisfied: pyCalverter in /opt/conda/lib/python3.7/site-packages (from workalendar~=14.1.0->pandora==0.1.0) (1.6.1)\n",
      "Requirement already satisfied: lunardate in /opt/conda/lib/python3.7/site-packages (from workalendar~=14.1.0->pandora==0.1.0) (0.2.0)\n",
      "Requirement already satisfied: skyfield-data in /opt/conda/lib/python3.7/site-packages (from workalendar~=14.1.0->pandora==0.1.0) (3.0.0)\n",
      "Requirement already satisfied: pyluach in /opt/conda/lib/python3.7/site-packages (from workalendar~=14.1.0->pandora==0.1.0) (1.2.1)\n",
      "Requirement already satisfied: skyfield in /opt/conda/lib/python3.7/site-packages (from workalendar~=14.1.0->pandora==0.1.0) (1.36)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from category-encoders~=2.2.2->pandora==0.1.0) (0.11.0)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /opt/conda/lib/python3.7/site-packages (from category-encoders~=2.2.2->pandora==0.1.0) (0.5.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas~=1.2.1->pandora==0.1.0) (1.14.0)\n",
      "Requirement already satisfied: jplephem>=2.13 in /opt/conda/lib/python3.7/site-packages (from skyfield->workalendar~=14.1.0->pandora==0.1.0) (2.15)\n",
      "Requirement already satisfied: sgp4>=2.2 in /opt/conda/lib/python3.7/site-packages (from skyfield->workalendar~=14.1.0->pandora==0.1.0) (2.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from skyfield->workalendar~=14.1.0->pandora==0.1.0) (2019.11.28)\n",
      "Building wheels for collected packages: pandora\n",
      "  Building wheel for pandora (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pandora: filename=pandora-0.1.0-py3-none-any.whl size=2681412 sha256=a8a2b844b431abe5e49a7a1f849e786de880ce38212b14158b10b302fdfd99a6\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-y0hoxu0m/wheels/01/8b/d5/a72c927a738750e04a4bb4fd22f63b4b88c7b5871732e2d67b\n",
      "Successfully built pandora\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/rbilleci/pandora.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import pandora\n",
    "import pandora.data.age_distribution as age_dist\n",
    "import pandora.data.oxford_data as oxford\n",
    "import pandora.data.population as population\n",
    "import pandora.data.temperatures as temperatures\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "from pandora.data import geo, continent, country_code, working_day\n",
    "from pandora import loader, encoders\n",
    "from pandora.core_fields import DATE, COUNTRY_CODE\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from logging import INFO, basicConfig, info\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup logging\n",
    "basicConfig(level=INFO, format='%(asctime)s\\t%(levelname)s\\t%(filename)s\\t%(message)s')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)  # ignore FutureWarning from scikit learn\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_info_columns = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandora.data.oxford_data_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 00:19:24,128\tINFO\tloader.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/geo.csv - loading\n",
      "2021-02-12 00:19:29,357\tINFO\tloader.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/country_code.csv - loading\n",
      "2021-02-12 00:19:33,491\tINFO\tloader.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/continent.csv - loading\n",
      "2021-02-12 00:19:37,678\tINFO\tloader.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/population.csv - loading\n",
      "2021-02-12 00:19:42,330\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/population.csv - imputing population\n",
      "2021-02-12 00:19:43,062\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/population.csv - imputing population_density\n",
      "2021-02-12 00:19:43,582\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/population.csv - imputing population_percent_urban\n",
      "2021-02-12 00:19:44,070\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/population.csv - imputing gdp_per_capita\n",
      "2021-02-12 00:19:44,539\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/population.csv - imputing obesity_rate\n",
      "2021-02-12 00:19:45,651\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/population.csv - imputing pneumonia_deaths_per_100k\n",
      "2021-02-12 00:19:46,740\tINFO\tloader.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/age_distribution.csv - loading\n",
      "2021-02-12 00:19:51,436\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/age_distribution.csv - imputing age_distribution_00_04\n",
      "2021-02-12 00:19:52,663\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/age_distribution.csv - imputing age_distribution_05_14\n",
      "2021-02-12 00:19:53,863\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/age_distribution.csv - imputing age_distribution_15_34\n",
      "2021-02-12 00:19:55,071\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/age_distribution.csv - imputing age_distribution_34_64\n",
      "2021-02-12 00:19:56,280\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/age_distribution.csv - imputing age_distribution_65_plus\n",
      "2021-02-12 00:19:57,481\tINFO\tloader.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/temperatures.csv - loading\n",
      "2021-02-12 00:20:02,692\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/temperatures.csv - imputing temperature\n",
      "2021-02-12 00:20:02,697\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/temperatures.csv - imputing specific_humidity\n",
      "2021-02-12 00:20:02,717\tINFO\tloader.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/oxford_data.csv - loading\n",
      "2021-02-12 00:20:06,346\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/oxford_data.csv - imputing confirmed_cases\n",
      "2021-02-12 00:20:07,255\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/oxford_data.csv - imputing confirmed_deaths\n",
      "2021-02-12 00:20:08,187\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/oxford_data.csv - imputing c1_school_closing\n",
      "2021-02-12 00:20:09,046\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/oxford_data.csv - imputing c2_workplace_closing\n",
      "2021-02-12 00:20:09,948\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/oxford_data.csv - imputing c3_cancel_public_events\n",
      "2021-02-12 00:20:10,856\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/oxford_data.csv - imputing c4_restrictions_on_gatherings\n",
      "2021-02-12 00:20:11,766\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/oxford_data.csv - imputing c5_close_public_transport\n",
      "2021-02-12 00:20:12,617\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/oxford_data.csv - imputing c6_stay_at_home_requirements\n",
      "2021-02-12 00:20:13,518\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/oxford_data.csv - imputing c7_restrictions_on_internal_movement\n",
      "2021-02-12 00:20:14,424\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/oxford_data.csv - imputing c8_international_travel_controls\n",
      "2021-02-12 00:20:15,270\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/oxford_data.csv - imputing h1_public_information_campaigns\n",
      "2021-02-12 00:20:16,181\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/oxford_data.csv - imputing h2_testing_policy\n",
      "2021-02-12 00:20:17,109\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/oxford_data.csv - imputing h3_contact_tracing\n",
      "2021-02-12 00:20:17,958\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/oxford_data.csv - imputing h6_facial_coverings\n",
      "2021-02-12 00:20:18,889\tINFO\tloader.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/working_day.csv - loading\n",
      "2021-02-12 00:20:24,921\tINFO\timputer.py\t/opt/conda/lib/python3.7/site-packages/pandora/data/working_day.csv - imputing working_day\n",
      "2021-02-12 00:20:27,234\tINFO\tloader.py\tvalidating fields\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# determine the last date we have from the oxford data set\n",
    "# which is the first day we'll begin prediction from\n",
    "prediction_start_date = pd.read_csv(oxford.module.location, keep_default_na=False, na_values='')['date'].max()\n",
    "prediction_start_date = datetime.datetime.strptime(prediction_start_date, '%Y-%m-%d').date()\n",
    "\n",
    "# max number of days to create, build outs the dataframe\n",
    "# which will have placeholder values we want to predict for\n",
    "days_to_predict = 180\n",
    "\n",
    "# the data range should cover the ground truth data + the time window we are predicting into\n",
    "start_date = datetime.date(2020, 1, 1)\n",
    "end_date = prediction_start_date + datetime.timedelta(days=days_to_predict)\n",
    "\n",
    "# the imputation window might extend far before or after\n",
    "# the range we are predicting, this is so we have more data samples for imputation calculations\n",
    "imputation_window_start_date =  datetime.date(2020, 1, 1)\n",
    "imputation_window_end_date =  datetime.date(2021, 12, 31)\n",
    "\n",
    "# load the data\n",
    "df = loader.load(start_date,\n",
    "                 end_date,\n",
    "                 imputation_window_start_date,\n",
    "                 imputation_window_end_date,\n",
    "                 geo.module,\n",
    "                 [\n",
    "                     country_code.module,\n",
    "                     continent.module,\n",
    "                     population.module,\n",
    "                     age_dist.module,\n",
    "                     temperatures.module,\n",
    "                     oxford.module,\n",
    "                     working_day.module\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add computed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ma(field, window_size):\n",
    "    df[f\"{field}_ma_{window_size}\"] = df.groupby('geo_code')[field].rolling(window_size, center=False).mean().fillna(0).reset_index(0, drop=True)\n",
    "\n",
    "def add_working_day_tomorrow(grouped):\n",
    "    grouped['working_day' + '_tomorrow'] = grouped['working_day'].copy().shift(-1).bfill().ffill()\n",
    "    return grouped\n",
    "\n",
    "\n",
    "def add_working_day_yesterday(grouped):\n",
    "    grouped['working_day' + '_yesterday'] = grouped['working_day'].copy().shift(1).bfill().ffill()\n",
    "    return grouped\n",
    "\n",
    "def transform_column_order(df):\n",
    "    df = df.reindex(sorted(df.columns), axis=1)  # Sort columns by name\n",
    "    df_label = df['predicted_new_cases']\n",
    "    df = df.drop(labels=['predicted_new_cases'], axis=1)\n",
    "    df.insert(0, 'predicted_new_cases', df_label)\n",
    "    return df\n",
    "\n",
    "# Compute number of new cases and deaths each day\n",
    "# Replace negative values (which do not make sense for these columns) with 0\n",
    "df['new_cases'] = df.groupby('geo_code').confirmed_cases.diff().fillna(0)\n",
    "df['new_cases'] = df['new_cases'].clip(lower=0)\n",
    "\n",
    "# add predicted new cases\n",
    "df['predicted_new_cases'] = df.groupby('geo_code').new_cases.shift(-1).fillna(0)\n",
    "df['predicted_new_cases'] = df['predicted_new_cases'].clip(lower=0)\n",
    "\n",
    "# add confirmed cases as percent of population\n",
    "df['new_cases_as_percent_of_population'] = df['new_cases'] / df['population']\n",
    "df['confirmed_cases_as_percent_of_population'] = df['confirmed_cases'] / df['population']\n",
    "\n",
    "# Add moving averages\n",
    "for window_size in [3, 7, 21]:\n",
    "    compute_ma('new_cases', window_size)\n",
    "    compute_ma('confirmed_cases', window_size)\n",
    "    compute_ma('specific_humidity', window_size)    \n",
    "    compute_ma('c1_school_closing', window_size)        \n",
    "    compute_ma('c2_workplace_closing', window_size)        \n",
    "    compute_ma('c3_cancel_public_events', window_size)        \n",
    "    compute_ma('c4_restrictions_on_gatherings', window_size)   \n",
    "    compute_ma('c5_close_public_transport', window_size)        \n",
    "    compute_ma('c6_stay_at_home_requirements', window_size)        \n",
    "    compute_ma('c7_restrictions_on_internal_movement', window_size)        \n",
    "    compute_ma('c8_international_travel_controls', window_size)   \n",
    "    compute_ma('h1_public_information_campaigns', window_size)        \n",
    "    compute_ma('h2_testing_policy', window_size)        \n",
    "    compute_ma('h3_contact_tracing', window_size)        \n",
    "    compute_ma('h6_facial_coverings', window_size)     \n",
    "    compute_ma('working_day', window_size)        \n",
    "\n",
    "# Add working day information for tomorrow, and today\n",
    "df = df.groupby('geo_code').apply(lambda group: add_working_day_tomorrow(group)).reset_index(drop=True)\n",
    "df = df.groupby('geo_code').apply(lambda group: add_working_day_yesterday(group)).reset_index(drop=True)\n",
    "df['npi_sum'] = df['c1_school_closing'] + df['c2_workplace_closing'] + \\\n",
    "                df['c3_cancel_public_events'] + df['c4_restrictions_on_gatherings'] + \\\n",
    "                df['c5_close_public_transport'] + df['c6_stay_at_home_requirements'] + \\\n",
    "                df['c7_restrictions_on_internal_movement'] + df['c8_international_travel_controls'] + \\\n",
    "                df['h1_public_information_campaigns'] + df['h2_testing_policy'] + \\\n",
    "                df['h3_contact_tracing'] + df['h6_facial_coverings']\n",
    "\n",
    "# Add a column to indicate ground-truth data vs predicted data\n",
    "df['predicted'] = df['date'].apply(lambda x: x >= prediction_start_date)\n",
    "\n",
    "# Drop unused columns\n",
    "df = transform_column_order(df)\n",
    "df = df.sort_values(['geo_code', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('temp').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "df.to_csv('temp/01-data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
