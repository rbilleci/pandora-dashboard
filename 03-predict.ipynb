{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Search Update Notebook\n",
    "\n",
    "This notebook is used to update the elastic search index with the latest datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.7/site-packages (1.3.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.18.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.4.1)\n",
      "Collecting git+https://github.com/rbilleci/pandora.git\n",
      "  Cloning https://github.com/rbilleci/pandora.git to /tmp/pip-req-build-a7w_ctbc\n",
      "  Running command git clone -q https://github.com/rbilleci/pandora.git /tmp/pip-req-build-a7w_ctbc\n",
      "Requirement already satisfied (use --upgrade to upgrade): pandora==0.1.0 from git+https://github.com/rbilleci/pandora.git in /opt/conda/lib/python3.7/site-packages\n",
      "Requirement already satisfied: pandas~=1.2.1 in /opt/conda/lib/python3.7/site-packages (from pandora==0.1.0) (1.2.2)\n",
      "Requirement already satisfied: fnvhash~=0.1.0 in /opt/conda/lib/python3.7/site-packages (from pandora==0.1.0) (0.1.0)\n",
      "Requirement already satisfied: scikit-learn~=0.24.1 in /opt/conda/lib/python3.7/site-packages (from pandora==0.1.0) (0.24.1)\n",
      "Requirement already satisfied: workalendar~=14.1.0 in /opt/conda/lib/python3.7/site-packages (from pandora==0.1.0) (14.1.0)\n",
      "Requirement already satisfied: category-encoders~=2.2.2 in /opt/conda/lib/python3.7/site-packages (from pandora==0.1.0) (2.2.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas~=1.2.1->pandora==0.1.0) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas~=1.2.1->pandora==0.1.0) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.7/site-packages (from pandas~=1.2.1->pandora==0.1.0) (1.18.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn~=0.24.1->pandora==0.1.0) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn~=0.24.1->pandora==0.1.0) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn~=0.24.1->pandora==0.1.0) (2.1.0)\n",
      "Requirement already satisfied: skyfield-data in /opt/conda/lib/python3.7/site-packages (from workalendar~=14.1.0->pandora==0.1.0) (3.0.0)\n",
      "Requirement already satisfied: pyluach in /opt/conda/lib/python3.7/site-packages (from workalendar~=14.1.0->pandora==0.1.0) (1.2.1)\n",
      "Requirement already satisfied: skyfield in /opt/conda/lib/python3.7/site-packages (from workalendar~=14.1.0->pandora==0.1.0) (1.36)\n",
      "Requirement already satisfied: lunardate in /opt/conda/lib/python3.7/site-packages (from workalendar~=14.1.0->pandora==0.1.0) (0.2.0)\n",
      "Requirement already satisfied: pyCalverter in /opt/conda/lib/python3.7/site-packages (from workalendar~=14.1.0->pandora==0.1.0) (1.6.1)\n",
      "Requirement already satisfied: setuptools>=1.0 in /opt/conda/lib/python3.7/site-packages (from workalendar~=14.1.0->pandora==0.1.0) (45.2.0.post20200210)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /opt/conda/lib/python3.7/site-packages (from category-encoders~=2.2.2->pandora==0.1.0) (0.5.1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from category-encoders~=2.2.2->pandora==0.1.0) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas~=1.2.1->pandora==0.1.0) (1.14.0)\n",
      "Requirement already satisfied: jplephem>=2.13 in /opt/conda/lib/python3.7/site-packages (from skyfield->workalendar~=14.1.0->pandora==0.1.0) (2.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from skyfield->workalendar~=14.1.0->pandora==0.1.0) (2019.11.28)\n",
      "Requirement already satisfied: sgp4>=2.2 in /opt/conda/lib/python3.7/site-packages (from skyfield->workalendar~=14.1.0->pandora==0.1.0) (2.15)\n",
      "Building wheels for collected packages: pandora\n",
      "  Building wheel for pandora (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pandora: filename=pandora-0.1.0-py3-none-any.whl size=2681412 sha256=c3747069c2561901e403d263153eb5ed96c5ab86d6f89b30d892701e81850a19\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-2gablfqc/wheels/01/8b/d5/a72c927a738750e04a4bb4fd22f63b4b88c7b5871732e2d67b\n",
      "Successfully built pandora\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "!pip install git+https://github.com/rbilleci/pandora.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "from pandora import loader, encoders\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from logging import INFO, basicConfig, info\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup logging\n",
    "basicConfig(level=INFO, format='%(asctime)s\\t%(levelname)s\\t%(filename)s\\t%(message)s')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)  # ignore FutureWarning from scikit learn\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_info_columns = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (98) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# load the dataset and set the date column\n",
    "df = pd.read_csv('temp/01-data.csv', keep_default_na=False, na_values='')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# determine the date where prediction should begin\n",
    "prediction_start_date = df[df['predicted'] == True]['date'].min().date()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 95580 entries, 0 to 138114\n",
      "Data columns (total 134 columns):\n",
      " #    Column                                          Non-Null Count  Dtype         \n",
      "---   ------                                          --------------  -----         \n",
      " 0    predicted_new_cases                             95580 non-null  float64       \n",
      " 1    age_distribution_00_04                          95580 non-null  float64       \n",
      " 2    age_distribution_05_14                          95580 non-null  float64       \n",
      " 3    age_distribution_15_34                          95580 non-null  float64       \n",
      " 4    age_distribution_34_64                          95580 non-null  float64       \n",
      " 5    age_distribution_65_plus                        95580 non-null  float64       \n",
      " 6    c1_school_closing                               95580 non-null  float64       \n",
      " 7    c1_school_closing_ma_21                         95580 non-null  float64       \n",
      " 8    c1_school_closing_ma_3                          95580 non-null  float64       \n",
      " 9    c1_school_closing_ma_7                          95580 non-null  float64       \n",
      " 10   c2_workplace_closing                            95580 non-null  float64       \n",
      " 11   c2_workplace_closing_ma_21                      95580 non-null  float64       \n",
      " 12   c2_workplace_closing_ma_3                       95580 non-null  float64       \n",
      " 13   c2_workplace_closing_ma_7                       95580 non-null  float64       \n",
      " 14   c3_cancel_public_events                         95580 non-null  float64       \n",
      " 15   c3_cancel_public_events_ma_21                   95580 non-null  float64       \n",
      " 16   c3_cancel_public_events_ma_3                    95580 non-null  float64       \n",
      " 17   c3_cancel_public_events_ma_7                    95580 non-null  float64       \n",
      " 18   c4_restrictions_on_gatherings                   95580 non-null  float64       \n",
      " 19   c4_restrictions_on_gatherings_ma_21             95580 non-null  float64       \n",
      " 20   c4_restrictions_on_gatherings_ma_3              95580 non-null  float64       \n",
      " 21   c4_restrictions_on_gatherings_ma_7              95580 non-null  float64       \n",
      " 22   c5_close_public_transport                       95580 non-null  float64       \n",
      " 23   c5_close_public_transport_ma_21                 95580 non-null  float64       \n",
      " 24   c5_close_public_transport_ma_3                  95580 non-null  float64       \n",
      " 25   c5_close_public_transport_ma_7                  95580 non-null  float64       \n",
      " 26   c6_stay_at_home_requirements                    95580 non-null  float64       \n",
      " 27   c6_stay_at_home_requirements_ma_21              95580 non-null  float64       \n",
      " 28   c6_stay_at_home_requirements_ma_3               95580 non-null  float64       \n",
      " 29   c6_stay_at_home_requirements_ma_7               95580 non-null  float64       \n",
      " 30   c7_restrictions_on_internal_movement            95580 non-null  float64       \n",
      " 31   c7_restrictions_on_internal_movement_ma_21      95580 non-null  float64       \n",
      " 32   c7_restrictions_on_internal_movement_ma_3       95580 non-null  float64       \n",
      " 33   c7_restrictions_on_internal_movement_ma_7       95580 non-null  float64       \n",
      " 34   c8_international_travel_controls                95580 non-null  float64       \n",
      " 35   c8_international_travel_controls_ma_21          95580 non-null  float64       \n",
      " 36   c8_international_travel_controls_ma_3           95580 non-null  float64       \n",
      " 37   c8_international_travel_controls_ma_7           95580 non-null  float64       \n",
      " 38   confirmed_cases                                 95580 non-null  float64       \n",
      " 39   confirmed_cases--                               95580 non-null  bool          \n",
      " 40   confirmed_cases_as_percent_of_population        95580 non-null  float64       \n",
      " 41   confirmed_cases_as_percent_of_population_ma_21  95580 non-null  float64       \n",
      " 42   confirmed_cases_as_percent_of_population_ma_3   95580 non-null  float64       \n",
      " 43   confirmed_cases_as_percent_of_population_ma_7   95580 non-null  float64       \n",
      " 44   confirmed_cases_ma_21                           95580 non-null  float64       \n",
      " 45   confirmed_cases_ma_3                            95580 non-null  float64       \n",
      " 46   confirmed_cases_ma_7                            95580 non-null  float64       \n",
      " 47   date                                            95580 non-null  datetime64[ns]\n",
      " 48   gdp_per_capita                                  95580 non-null  float64       \n",
      " 49   gdp_per_capita--                                95580 non-null  bool          \n",
      " 50   h1_public_information_campaigns                 95580 non-null  float64       \n",
      " 51   h1_public_information_campaigns_ma_21           95580 non-null  float64       \n",
      " 52   h1_public_information_campaigns_ma_3            95580 non-null  float64       \n",
      " 53   h1_public_information_campaigns_ma_7            95580 non-null  float64       \n",
      " 54   h2_testing_policy                               95580 non-null  float64       \n",
      " 55   h2_testing_policy_ma_21                         95580 non-null  float64       \n",
      " 56   h2_testing_policy_ma_3                          95580 non-null  float64       \n",
      " 57   h2_testing_policy_ma_7                          95580 non-null  float64       \n",
      " 58   h3_contact_tracing                              95580 non-null  float64       \n",
      " 59   h3_contact_tracing_ma_21                        95580 non-null  float64       \n",
      " 60   h3_contact_tracing_ma_3                         95580 non-null  float64       \n",
      " 61   h3_contact_tracing_ma_7                         95580 non-null  float64       \n",
      " 62   h6_facial_coverings                             95580 non-null  float64       \n",
      " 63   h6_facial_coverings_ma_21                       95580 non-null  float64       \n",
      " 64   h6_facial_coverings_ma_3                        95580 non-null  float64       \n",
      " 65   h6_facial_coverings_ma_7                        95580 non-null  float64       \n",
      " 66   new_cases                                       95580 non-null  float64       \n",
      " 67   new_cases_as_percent_of_population              95580 non-null  float64       \n",
      " 68   new_cases_as_percent_of_population_ma_21        95580 non-null  float64       \n",
      " 69   new_cases_as_percent_of_population_ma_3         95580 non-null  float64       \n",
      " 70   new_cases_as_percent_of_population_ma_7         95580 non-null  float64       \n",
      " 71   new_cases_ma_21                                 95580 non-null  float64       \n",
      " 72   new_cases_ma_3                                  95580 non-null  float64       \n",
      " 73   new_cases_ma_7                                  95580 non-null  float64       \n",
      " 74   npi_sum                                         95580 non-null  float64       \n",
      " 75   obesity_rate                                    95580 non-null  float64       \n",
      " 76   obesity_rate--                                  95580 non-null  bool          \n",
      " 77   pneumonia_deaths_per_100k                       95580 non-null  float64       \n",
      " 78   pneumonia_deaths_per_100k--                     95580 non-null  bool          \n",
      " 79   population                                      95580 non-null  float64       \n",
      " 80   population--                                    95580 non-null  bool          \n",
      " 81   population_density                              95580 non-null  float64       \n",
      " 82   population_density--                            95580 non-null  bool          \n",
      " 83   population_percent_urban                        95580 non-null  float64       \n",
      " 84   population_percent_urban--                      95580 non-null  bool          \n",
      " 85   specific_humidity                               95580 non-null  float64       \n",
      " 86   specific_humidity_ma_21                         95580 non-null  float64       \n",
      " 87   specific_humidity_ma_3                          95580 non-null  float64       \n",
      " 88   specific_humidity_ma_7                          95580 non-null  float64       \n",
      " 89   temperature                                     95580 non-null  float64       \n",
      " 90   temperature_ma_21                               95580 non-null  float64       \n",
      " 91   temperature_ma_3                                95580 non-null  float64       \n",
      " 92   temperature_ma_7                                95580 non-null  float64       \n",
      " 93   working_day                                     95580 non-null  float64       \n",
      " 94   working_day--                                   95580 non-null  bool          \n",
      " 95   working_day_ma_21                               95580 non-null  float64       \n",
      " 96   working_day_ma_3                                95580 non-null  float64       \n",
      " 97   working_day_ma_7                                95580 non-null  float64       \n",
      " 98   working_day_tomorrow                            95580 non-null  float64       \n",
      " 99   working_day_yesterday                           95580 non-null  float64       \n",
      " 100  year                                            95580 non-null  int64         \n",
      " 101  date_day                                        95580 non-null  int64         \n",
      " 102  continent_bin_0                                 95580 non-null  int64         \n",
      " 103  continent_bin_1                                 95580 non-null  int64         \n",
      " 104  continent_bin_2                                 95580 non-null  int64         \n",
      " 105  continent_bin_3                                 95580 non-null  int64         \n",
      " 106  geo_code_bin_0                                  95580 non-null  int64         \n",
      " 107  geo_code_bin_1                                  95580 non-null  int64         \n",
      " 108  geo_code_bin_2                                  95580 non-null  int64         \n",
      " 109  geo_code_bin_3                                  95580 non-null  int64         \n",
      " 110  geo_code_bin_4                                  95580 non-null  int64         \n",
      " 111  geo_code_bin_5                                  95580 non-null  int64         \n",
      " 112  geo_code_bin_6                                  95580 non-null  int64         \n",
      " 113  geo_code_bin_7                                  95580 non-null  int64         \n",
      " 114  geo_code_bin_8                                  95580 non-null  int64         \n",
      " 115  country_code_bin_0                              95580 non-null  int64         \n",
      " 116  country_code_bin_1                              95580 non-null  int64         \n",
      " 117  country_code_bin_2                              95580 non-null  int64         \n",
      " 118  country_code_bin_3                              95580 non-null  int64         \n",
      " 119  country_code_bin_4                              95580 non-null  int64         \n",
      " 120  country_code_bin_5                              95580 non-null  int64         \n",
      " 121  country_code_bin_6                              95580 non-null  int64         \n",
      " 122  country_code_bin_7                              95580 non-null  int64         \n",
      " 123  country_code_bin_8                              95580 non-null  int64         \n",
      " 124  day_of_week_bin_0                               95580 non-null  int64         \n",
      " 125  day_of_week_bin_1                               95580 non-null  int64         \n",
      " 126  day_of_week_bin_2                               95580 non-null  int64         \n",
      " 127  day_of_week_bin_3                               95580 non-null  int64         \n",
      " 128  day_of_week_sin                                 95580 non-null  float64       \n",
      " 129  day_of_week_cos                                 95580 non-null  float64       \n",
      " 130  day_of_month_sin                                95580 non-null  float64       \n",
      " 131  day_of_month_cos                                95580 non-null  float64       \n",
      " 132  day_of_year_sin                                 95580 non-null  float64       \n",
      " 133  day_of_year_cos                                 95580 non-null  float64       \n",
      "dtypes: bool(8), datetime64[ns](1), float64(97), int64(28)\n",
      "memory usage: 95.4 MB\n"
     ]
    }
   ],
   "source": [
    "# only work within the specified range\n",
    "df_ml = df.loc[df['date'] < pd.to_datetime(prediction_start_date)]\n",
    "enc = {}\n",
    "enc['continent'] = encoders.BinaryEncoder('continent')\n",
    "enc['geo_code'] = encoders.BinaryEncoder('geo_code')\n",
    "enc['country_code'] = encoders.BinaryEncoder('country_code')\n",
    "enc['day_of_week'] = encoders.BinaryEncoder('day_of_week')\n",
    "enc['day_of_week_cyc'] = encoders.CyclicalEncoder('day_of_week')\n",
    "enc['day_of_month'] = encoders.BinaryEncoder('day_of_month')\n",
    "enc['day_of_month_cyc'] = encoders.CyclicalEncoder('day_of_month')\n",
    "enc['day_of_year'] = encoders.BinaryEncoder('day_of_year')\n",
    "enc['day_of_year_cyc'] = encoders.CyclicalEncoder('day_of_year')\n",
    "\n",
    "def encode(df_x, fit):\n",
    "    # convert the date to an integer value\n",
    "    df_x['date_day'] = df_x['date'].apply(lambda x: x.day)\n",
    "\n",
    "    # encode the geo data\n",
    "    if fit:\n",
    "        df_x = enc['continent'].fit_transform(df_x)\n",
    "        df_x = enc['geo_code'].fit_transform(df_x)\n",
    "        df_x = enc['country_code'].fit_transform(df_x)\n",
    "    else:\n",
    "        df_x = enc['continent'].transform(df_x)\n",
    "        df_x = enc['geo_code'].transform(df_x)\n",
    "        df_x = enc['country_code'].transform(df_x)\n",
    "    if fit:\n",
    "        df_x = enc['day_of_week'].fit_transform(df_x)\n",
    "        df_x['day_of_week'] = df_x['day_of_week'] / 7.0\n",
    "        df_x = enc['day_of_week_cyc'].fit_transform(df_x)\n",
    "    else:\n",
    "        df_x = enc['day_of_week'].transform(df_x)\n",
    "        df_x['day_of_week'] = df_x['day_of_week'] / 7.0\n",
    "        df_x = enc['day_of_week_cyc'].transform(df_x)\n",
    "    if fit:\n",
    "        df_x['day_of_month'] = df_x['day_of_month'] / 31.0 # keep it simple\n",
    "        df_x = enc['day_of_month_cyc'].fit_transform(df_x)\n",
    "        df_x['day_of_year'] = df_x['day_of_year'] / 366.0 # keep it simple\n",
    "        df_x = enc['day_of_year_cyc'].fit_transform(df_x)\n",
    "    else:\n",
    "        df_x['day_of_month'] = df_x['day_of_month'] / 31.0 # keep it simple\n",
    "        df_x = enc['day_of_month_cyc'].transform(df_x)\n",
    "        df_x['day_of_year'] = df_x['day_of_year'] / 366.0 # keep it simple\n",
    "        df_x = enc['day_of_year_cyc'].transform(df_x)\n",
    "        \n",
    "    \n",
    "    # drop unused columns\n",
    "    df_x = df_x.drop(labels=['country_name',\n",
    "                           'continent',\n",
    "                           'geo_code',\n",
    "                           'country_code',\n",
    "                           'day_of_week',\n",
    "                           'day_of_month',\n",
    "                           'day_of_year',\n",
    "                            'country_code3',\n",
    "                            'country_code_numeric',\n",
    "                            'confirmed_deaths',\n",
    "                            'predicted',\n",
    "                            'region_name',\n",
    "                            'month',                           \n",
    "                            'quarter',\n",
    "                            'week'], axis=1)\n",
    "    return df_x\n",
    "\n",
    "df_ml = encode(df_ml, fit=True)\n",
    "df_ml.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the train, val, test split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Range:   2020-01-01 - 2020-12-25\n",
      "Validation Range: 2020-12-26 - 2021-01-25\n",
      "Test Range:       2021-01-26 - 2021-02-08\n"
     ]
    }
   ],
   "source": [
    "days_for_validation = 31\n",
    "days_for_test = 14\n",
    "\n",
    "def split(df: pd.DataFrame, \n",
    "          days_for_validation: int, \n",
    "          days_for_test: int) -> (pd.DataFrame, pd.DataFrame, pd.DataFrame):\n",
    "    \n",
    "    # First, sort the data by date\n",
    "    df = df.sort_values('date')\n",
    "\n",
    "    # Determine the maximum date\n",
    "    date_start_test = df['date'].max() - pd.to_timedelta(days_for_test - 1, unit='d')\n",
    "    date_start_validation = date_start_test - pd.to_timedelta(days_for_validation, unit='d')\n",
    "\n",
    "    df_train = df[df['date'] < date_start_validation]\n",
    "    df_validation = df[(df['date'] >= date_start_validation) & (df['date'] < date_start_test)]\n",
    "    df_test = df[df['date'] >= date_start_test]\n",
    "\n",
    "    # Debug the outpoint\n",
    "    print(f\"Training Range:   {df_train['date'].min().date()} - {df_train['date'].max().date()}\")\n",
    "    print(f\"Validation Range: {df_validation['date'].min().date()} - {df_validation['date'].max().date()}\")\n",
    "    print(f\"Test Range:       {df_test['date'].min().date()} - {df_test['date'].max().date()}\")\n",
    "\n",
    "    # Sanity Check\n",
    "    if len(df.index) != len(df_train.index) + len(df_validation.index) + len(df_test.index):\n",
    "        raise Exception('entries do not add up')\n",
    "\n",
    "    return df_train, df_validation, df_test\n",
    "\n",
    "df_train_prescaled, df_validation_prescaled, df_test_prescaled = split(df_ml, days_for_validation, days_for_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_prescaled.copy()\n",
    "df_validation = df_validation_prescaled.copy()\n",
    "df_test = df_test_prescaled.copy()\n",
    "\n",
    "scalers = {}\n",
    "\n",
    "\n",
    "for feature_name in df_ml.columns.values:\n",
    "    if feature_name == 'date' or feature_name == 'predicted_new_cases':\n",
    "        continue\n",
    "    scalers[feature_name] = StandardScaler()\n",
    "    df_train[feature_name] = scalers[feature_name].fit_transform(df_train_prescaled[[feature_name]])\n",
    "        \n",
    "if len(df_validation_prescaled) > 0:        \n",
    "    for feature_name in df_ml.columns.values:\n",
    "        if feature_name == 'date' or feature_name == 'predicted_new_cases':\n",
    "            continue\n",
    "        df_validation[feature_name] = scalers[feature_name].transform(df_validation_prescaled[[feature_name]])\n",
    "\n",
    "if len(df_test_prescaled) > 0:        \n",
    "    for feature_name in df_ml.columns.values:\n",
    "        if feature_name == 'date' or feature_name == 'predicted_new_cases':\n",
    "            continue        \n",
    "        df_test[feature_name] = scalers[feature_name].transform(df_test_prescaled[[feature_name]])\n",
    "\n",
    "df_train = df_train.drop(labels=['date'], axis=1)\n",
    "df_validation = df_validation.drop(labels=['date'], axis=1)\n",
    "df_test = df_test.drop(labels=['date'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:8091.68066\ttrain-rmse:4131.48633\n",
      "[10]\teval-rmse:4195.98486\ttrain-rmse:3324.66919\n",
      "[20]\teval-rmse:4029.15161\ttrain-rmse:3270.61499\n",
      "[30]\teval-rmse:4028.06714\ttrain-rmse:3254.31982\n",
      "[40]\teval-rmse:4027.02539\ttrain-rmse:3247.43579\n",
      "[50]\teval-rmse:4021.57471\ttrain-rmse:3243.72827\n",
      "[60]\teval-rmse:4013.83936\ttrain-rmse:3241.34839\n",
      "[70]\teval-rmse:4005.06616\ttrain-rmse:3239.60889\n",
      "[80]\teval-rmse:3995.98877\ttrain-rmse:3238.23267\n",
      "[90]\teval-rmse:3987.03931\ttrain-rmse:3237.09546\n",
      "[99]\teval-rmse:3979.31958\ttrain-rmse:3236.22241\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "params_tree = {\n",
    "    'nthread': 1,\n",
    "    'objective':'reg:squarederror',\n",
    "    'eta': 0.1\n",
    "}\n",
    "\n",
    "\n",
    "params_linear = {\n",
    "    \"booster\": \"gblinear\",\n",
    "    'nthread': 1,    \n",
    "    \"objective\": \"reg:squarederror\",\n",
    "}\n",
    "\n",
    "\n",
    "rounds = 100\n",
    "early_stopping_rounds = 10\n",
    "\n",
    "test_x, test_y = df_test.iloc[:, 1:], df_test.iloc[:, :1]\n",
    "dtest = xgb.DMatrix(data=test_x,label=test_y)\n",
    "callback_monitor = xgb.callback.EvaluationMonitor(rank=0, period=10, show_stdv=False)\n",
    "\n",
    "dtrain = xgb.DMatrix(data=df_train.iloc[:, 1:], label=df_train.iloc[:, :1])\n",
    "dvalidation = xgb.DMatrix(data=df_validation.iloc[:, 1:], label=df_validation.iloc[:, :1])\n",
    "watchlist = [(dvalidation, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "bst = xgb.train(params_linear, \n",
    "                dtrain, \n",
    "                rounds,\n",
    "                watchlist,\n",
    "                early_stopping_rounds=20,      \n",
    "                callbacks=[callback_monitor],\n",
    "                verbose_eval=False)\n",
    "bst.save_model('temp/predictor.model')\n",
    "predictions = bst.predict(dtest)\n",
    "score = mean_squared_error(test_y, predictions, squared=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4414.830713083968\n"
     ]
    }
   ],
   "source": [
    "predictions = bst.predict(dtest)\n",
    "score = mean_squared_error(test_y, predictions, squared=False)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rollout the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting from 2021-02-08 00:00:00 for 2021-02-09 00:00:00\n",
      "predicting from 2021-02-09 00:00:00 for 2021-02-10 00:00:00\n",
      "predicting from 2021-02-10 00:00:00 for 2021-02-11 00:00:00\n",
      "predicting from 2021-02-11 00:00:00 for 2021-02-12 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter the date range for the prediction window\n",
    "days_to_predict = 3\n",
    "date_to_predict_from = df[df['predicted'] == False]['date'].max()\n",
    "date_to_predict_to = date_to_predict_from + pd.to_timedelta(days_to_predict, unit='d')   \n",
    "\n",
    "df_predict = df.copy()\n",
    "df_predict = df_predict.sort_values(['date', 'geo_code'])\n",
    "df_predict = df_predict[df_predict['date'] >= pd.to_datetime(date_to_predict_from)]\n",
    "df_predict = df_predict[df_predict['date'] <= pd.to_datetime(date_to_predict_to)]\n",
    "\n",
    "def compute_ma(field, window_size):\n",
    "    df_predict[f\"{field}_ma_{window_size}\"] = df_predict.groupby('geo_code')[field].rolling(window_size, center=False).mean().fillna(0).reset_index(0, drop=True)\n",
    "\n",
    "\n",
    "def predict_day(group):\n",
    "    # get the geo code and values, we'll need to map back\n",
    "    # to the origial data frame for output\n",
    "    group = group.copy()\n",
    "    geo_codes = group['geo_code'].values\n",
    "    date_from = group['date'].max()\n",
    "    date_to = date_from + pd.to_timedelta(1, unit='d')   \n",
    "    \n",
    "    # determine the date we are predicting from encode and scale    \n",
    "    group = encode(group, False)\n",
    "    group = group.drop(labels=['date'], axis=1)\n",
    "    for scaler_name in scalers:\n",
    "        group[scaler_name] = scalers[scaler_name].transform(group[[scaler_name]])\n",
    "\n",
    "    # run the prediction algorithm\n",
    "    print(f\"predicting from {date_from} for {date_to}\")\n",
    "    gx, gy = group.iloc[:, 1:], group.iloc[:, :1]\n",
    "    dg = xgb.DMatrix(data=gx,label=gy)\n",
    "    predictions = bst.predict(dg)\n",
    "    \n",
    "    # apply the predictions to the NEXT day\n",
    "    for i in range(len(predictions)):\n",
    "        geo_code = geo_codes[i]\n",
    "        value = max(0, predictions[i])\n",
    "        filter_from = (df_predict['geo_code'] == geo_code) & (df_predict['date'] == date_from)        \n",
    "        filter_to = (df_predict['geo_code'] == geo_code) & (df_predict['date'] == date_to)        \n",
    "        df_predict.loc[filter_to, 'new_cases'] = value\n",
    "        df_predict.loc[filter_to, 'confirmed_cases'] = df_predict.loc[filter_from]['confirmed_cases'].max() + value\n",
    "\n",
    "    \n",
    "    # update the moving averages\n",
    "    for window_size in [3, 7, 21]:\n",
    "        compute_ma('new_cases', window_size)\n",
    "        compute_ma('confirmed_cases', window_size)\n",
    "        compute_ma('c1_school_closing', window_size)        \n",
    "        compute_ma('c2_workplace_closing', window_size)        \n",
    "        compute_ma('c3_cancel_public_events', window_size)        \n",
    "        compute_ma('c4_restrictions_on_gatherings', window_size)   \n",
    "        compute_ma('c5_close_public_transport', window_size)        \n",
    "        compute_ma('c6_stay_at_home_requirements', window_size)        \n",
    "        compute_ma('c7_restrictions_on_internal_movement', window_size)        \n",
    "        compute_ma('c8_international_travel_controls', window_size)   \n",
    "        compute_ma('h1_public_information_campaigns', window_size)        \n",
    "        compute_ma('h2_testing_policy', window_size)        \n",
    "        compute_ma('h3_contact_tracing', window_size)        \n",
    "        compute_ma('h6_facial_coverings', window_size)     \n",
    "        compute_ma('new_cases_as_percent_of_population', window_size)     \n",
    "        compute_ma('confirmed_cases_as_percent_of_population', window_size)     \n",
    "    \n",
    "\n",
    "# iterate on each day\n",
    "df_predict.groupby('date').apply(lambda group: predict_day(group))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>confirmed_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25602</th>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>4650.000000</td>\n",
       "      <td>2.296323e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25603</th>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>10087.440430</td>\n",
       "      <td>2.306410e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25604</th>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>8939.207031</td>\n",
       "      <td>2.315350e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25605</th>\n",
       "      <td>2021-02-11</td>\n",
       "      <td>7486.002441</td>\n",
       "      <td>2.322836e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     new_cases  confirmed_cases\n",
       "25602 2021-02-08   4650.000000     2.296323e+06\n",
       "25603 2021-02-09  10087.440430     2.306410e+06\n",
       "25604 2021-02-10   8939.207031     2.315350e+06\n",
       "25605 2021-02-11   7486.002441     2.322836e+06"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict.loc[df_predict['geo_code'] == 'DE'][['date', 'new_cases', 'confirmed_cases']].tail(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
